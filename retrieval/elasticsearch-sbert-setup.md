# Elasticsearch + Sentence-BERT 기반 검색 환경 구성 실험

## 실험 배경

기존 키워드 기반 검색으로는  
의미가 유사한 문서나 문장을 찾는 데 한계가 있었음.

이를 보완하기 위해  
Sentence-BERT(SBERT) 기반 임베딩과  
Elasticsearch 벡터 검색 조합을 실험함.

이 실험의 목적은 단순히  
“의미 검색이 되는가”가 아니라,

- AI 검색을 **실제 시스템에 적용할 수 있는지**
- 적용했을 때 **운영·설계 관점에서 어떤 판단이 필요한지**

를 확인하는 것이었음.

---

## 사용한 구성

### 임베딩
- Sentence-BERT (`sentence-transformers`)
- 문장 또는 텍스트 청크를 고정 길이 벡터로 변환
- 코사인 유사도 기반 비교

### 검색 엔진
- Elasticsearch 8.x
- 벡터 필드 기반 유사도 검색

### 실행 환경
- Anaconda (Python 3.12)
- 별도 Conda 환경 구성

---

## 환경 구성 요약

### Python 환경
- Anaconda 기반 독립 환경 구성
- 주요 패키지:
  - `transformers`
  - `sentence-transformers`
  - `mysql-connector-python`

### Elasticsearch
- RPM 기반 설치
- 외부 접근 허용 (`network.host: 0.0.0.0`)
- 보안 기능 비활성화 (실험 목적)
- HTTP 포트: 9200

> 설치 및 초기 구성 자체는 큰 문제 없이 진행됨

---

## 실제로 해보니

### 긍정적인 점
- 키워드 검색으로 찾기 어려운 문서도 검색 가능
- 의미 유사도 기반 검색 효과는 분명히 존재

### 문제점
- 검색 품질이 **임베딩 모델보다 청크 분할 방식에 크게 의존**
- 재인덱싱 비용이 큼
- Elasticsearch 설정 및 운영 복잡도 증가
- 단순 키워드 검색 대비 시스템 구성 난이도 상승

---

## 청크 분할(Chunking)에서 발생한 핵심 이슈

임베딩 기반 검색에서는  
**무엇을 얼마나 잘라서 임베딩하느냐**가  
검색 품질을 사실상 결정함.

- 청크가 너무 작은 경우  
  → 점수는 높지만 맥락 없는 결과가 나옴
- 청크가 너무 큰 경우  
  → 핵심이 희석되어 검색 정확도 저하
- 고정 크기 청크  
  → 데이터 성격에 따라 일관성 없음
- overlap 포함 청크  
  → 품질은 안정적이나 비용 증가

이 문제는 모델이나 검색 엔진이 아니라,  
**시스템 설계자가 결정해야 하는 영역**이었음.

---

## 운영 관점에서의 한계

- 임베딩 모델 또는 청크 전략 변경 시 전체 재처리 필요
- 벡터 검색 결과 점수가 직관적이지 않음
- 유사도 임계값(threshold)을 자동으로 정하기 어려움
- 장애 발생 시 원인 분석 및 디버깅 난이도 높음

---

## 사람이 개입해야 했던 지점

- 검색 목적에 따른 청크 단위 결정
- 유사도 점수 기준 설정
- 벡터 검색 실패 시 키워드 검색 fallback 전략 선택
- 운영 중 인덱스 재구성 여부 판단

---

## 정리

Elasticsearch + SBERT 조합은  
**의미 기반 검색을 구현하는 데는 분명히 효과적이었지만**,  
검색 품질의 핵심은 모델이 아니라 **청크 설계와 운영 판단**에 있었음.

“AI 검색이 된다”는 사실보다,  
**어디까지 자동화할 수 있고  
어디서 사람이 개입해야 하는지**를 명확히 인식하는 것이  
이 구조를 실제 시스템에서 유지하기 위한 핵심이라는 점을 확인한 실험이었음.


👉 [Sentence-BERT + Elasticsearch 설치 실험 노트](./_notes/sbert-elasticsearch-setup.md)
